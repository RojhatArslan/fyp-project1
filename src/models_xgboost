import pandas as pd
from pathlib import Path

from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


def train_xgboost(data_path: Path): #Train and evaluate an XGBoost regression model  using a time-based train/test split.
   

    df = pd.read_csv(data_path, parse_dates=["ds"])
    df = df.sort_values("ds").reset_index(drop=True)

    # Features and target
    X = df.drop(columns=["ds", "bookings"])
    y = df["bookings"]

    # Time-based split (80% train, 20% test)
    split_idx = int(len(df) * 0.8)
    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

    # Train model
    model = XGBRegressor(
        n_estimators=300, #Number of trees
        learning_rate=0.05, #how much each tree contributes to the final predcition
        max_depth=5,
        subsample=0.8, # Fraction of training rows used per tree
        colsample_bytree=0.8, # Fraction of features used per tree
        random_state=42, # Minimise squared error between predicted and actual bookings
        objective="reg:squarederror"
    )

    model.fit(X_train, y_train)

    # Predict
    y_pred = model.predict(X_test)

    # Evaluation metrics
    mae = mean_absolute_error(y_test, y_pred)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    r2 = r2_score(y_test, y_pred)

    print("XGBoost Results")
    print(f"MAE:  {mae:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"RÂ²:   {r2:.3f}")

    return {
        "model": "XGBoost",
        "MAE": mae,
        "RMSE": rmse,
        "R2": r2,
    }


if __name__ == "__main__":
    DATA = Path("data/processed/daily_features.csv")
    train_xgboost(DATA)