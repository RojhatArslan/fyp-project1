import pandas as pd
from pathlib import Path

from lightgbm import LGBMRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


def train_lightgbm(data_path: Path): #  Train and evaluate a LightGBM regression model using a time-based train/test split.
  

   
    df = pd.read_csv(data_path, parse_dates=["ds"])
    df = df.sort_values("ds").reset_index(drop=True)

    
    X = df.drop(columns=["ds", "bookings"])
    y = df["bookings"]

  
    split_idx = int(len(df) * 0.8)
    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

    
    model = LGBMRegressor(
        n_estimators=300,        # number of boosting trees
        learning_rate=0.05,      # contribution of each tree
        max_depth=5,             # limit tree depth to reduce overfitting
        subsample=0.8,           # use 80% of rows per tree
        colsample_bytree=0.8,    # use 80% of features per tree
        random_state=42          # reproducibility
    )

  
    model.fit(X_train, y_train)

   
    y_pred = model.predict(X_test)

    # Evaluate performance
    mae = mean_absolute_error(y_test, y_pred)  # Evaluate performance
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    r2 = r2_score(y_test, y_pred)

    print("LightGBM Results")
    print(f"MAE:  {mae:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"RÂ²:   {r2:.3f}")

    return {
        "model": "LightGBM",
        "MAE": mae,
        "RMSE": rmse,
        "R2": r2,
    }


if __name__ == "__main__":
    DATA = Path("data/processed/daily_features.csv")
    train_lightgbm(DATA)
